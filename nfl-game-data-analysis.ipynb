{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from category_encoders import LeaveOneOutEncoder\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from category_encoders import LeaveOneOutEncoder\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Go out and find a dataset of interest. It could be from one of the recommended resources or some other aggregation. Or it could be something that you scraped yourself. Just make sure that it has lots of variables, including an outcome of interest to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pro football reference game info\n",
    "\n",
    "        https://www.pro-football-reference.com/years/{1966-2017}/games.htm/games.htm#games::none\n",
    "\n",
    "\n",
    "* Odds - money line, open/close lines historic info\n",
    "\n",
    "        http://www.aussportsbetting.com/historical_data/nfl.xlsx\n",
    "    \n",
    "\n",
    "* Kaggle - NFL scores and betting data\n",
    "\n",
    "        https://www.kaggle.com/tobycrabtree/nfl-scores-and-betting-data\n",
    "        \n",
    "### Kaggle files:\n",
    "       \n",
    "* spreadspoke_scores.csv\n",
    "* nfl_stadiums.csv\n",
    "* nfl_teams.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs = []\n",
    "\n",
    "# Read seasons 2000 to 2017\n",
    "for year in range(2000,2018):\n",
    "    print(year)\n",
    "    url = \"https://www.pro-football-reference.com/years/\" + str(year) + \"/games.htm#games::none\"\n",
    "    ydf = pd.read_html(url)\n",
    "    ydf = ydf[0]\n",
    "    ydf['Year'] = year\n",
    "\n",
    "    all_dfs.append(ydf)\n",
    "    \n",
    "scores1_df = pd.concat(all_dfs)\n",
    "scores1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_df = pd.read_excel(\"http://www.aussportsbetting.com/historical_data/nfl.xlsx\")\n",
    "scores2_df = pd.read_csv('data/spreadspoke_scores.csv', encoding = \"ISO-8859-1\", engine='python')\n",
    "stadiums_df = pd.read_csv('data/nfl_stadiums.csv', encoding = \"ISO-8859-1\", engine='python')\n",
    "teams_df = pd.read_csv('data/nfl_teams.csv', encoding = \"ISO-8859-1\", engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pro football reference game info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1_df.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1_df = scores1_df.drop(columns=['Unnamed: 5', 'Unnamed: 7', 'Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1_df = scores1_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1_df['Date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mos = {'January': 1\n",
    "       ,'February': 2\n",
    "       ,'March': 3\n",
    "       ,'April': 4\n",
    "       ,'May': 5\n",
    "       ,'June': 6\n",
    "       ,'July': 7\n",
    "       ,'August': 8\n",
    "       ,'September': 9\n",
    "       ,'October': 10\n",
    "       ,'November': 11\n",
    "       ,'December': 12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = 'January'\n",
    "for m in mos:\n",
    "    if m != 'January':\n",
    "        match = match + '|' + m\n",
    "scores1_df = scores1_df[scores1_df['Date'].str.contains(match)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores1_df['Month'] = scores1_df['Date'].str.split(' ').str[0]\n",
    "scores1_df['DayofMonth'] = scores1_df['Date'].str.split(' ').str[1].astype(int)\n",
    "\n",
    "scores1_df['month_num'] = scores1_df['Month'].map(mos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Odds - money line, open/close lines historic info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_df.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_df['Overtime?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_df['Playoff Game?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_df['Neutral Venue?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_df['Overtime?'] = odds_df['Overtime?'].fillna('N')\n",
    "odds_df['Playoff Game?'] = odds_df['Playoff Game?'].fillna('N')\n",
    "odds_df['Playoff Game?'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_cols = ['Date'                       \n",
    "            ,'Home Team'                 \n",
    "            ,'Away Team'                 \n",
    "            ,'Home Score'                \n",
    "            ,'Away Score'               \n",
    "            ,'Overtime?'               \n",
    "            ,'Playoff Game?'                       \n",
    "            ,'Home Odds Open'             \n",
    "            ,'Away Odds Open'           \n",
    "            ,'Total Score Open']         \n",
    "odds_df = odds_df[odds_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_df['date'] = pd.to_datetime(odds_df['Date'])\n",
    "odds_df['year'] = odds_df['date'].dt.year\n",
    "odds_df['month'] = odds_df['date'].dt.month\n",
    "odds_df['DayofMonth'] = odds_df['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle - NFL scores and betting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2_df.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2_df = scores2_df.drop(columns = ['weather_humidity', 'weather_detail', 'schedule_playoff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2_df = scores2_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2_df['DayofMonth'] = pd.to_datetime(scores2_df['schedule_date']).dt.day\n",
    "scores2_df['Month'] = pd.to_datetime(scores2_df['schedule_date']).dt.month\n",
    "scores2_df['year'] = pd.to_datetime(scores2_df['schedule_date']).dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add winning team column based on scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2_df['Winner'] = scores2_df['team_home']\n",
    "\n",
    "scores2_df.loc[scores2_df['score_away'] > scores2_df['score_home'], \n",
    "               \"Winner\"] = scores2_df['team_away']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NFL staduims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stadiums_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stadiums_df.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['stadium_name', 'stadium_location', 'stadium_type', 'stadium_weather_type', 'stadium_surface']\n",
    "stadiums_df = stadiums_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stadiums_df.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stadiums_df['stadium_type'] = stadiums_df['stadium_type'].fillna('unknown')\n",
    "stadiums_df['stadium_weather_type'] = stadiums_df['stadium_weather_type'].fillna('unknown')\n",
    "stadiums_df['stadium_surface'] = stadiums_df['stadium_surface'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stadiums_df.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stadiums_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NFL teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df.head(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df.isna().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df['team_division'] = teams_df['team_division'].fillna(teams_df['team_division_pre2002'])\n",
    "teams_df['team_division'] = teams_df['team_division'].fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df = teams_df.drop(columns=['team_conference_pre2002', 'team_division_pre2002', 'team_id_pfr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join dataframes together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores1_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table = scores1_df.merge(scores2_df,\n",
    "                              left_on=['month_num', 'DayofMonth', 'Year', 'Winner/tie'], \n",
    "                              right_on=['Month', 'DayofMonth', 'year', 'Winner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table[['Date', 'Winner/tie', 'Winner', 'PtsW', 'PtsL', 'score_home', 'score_away']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table = full_table.merge(odds_df,\n",
    "                              left_on=['month_num', 'DayofMonth', 'year', 'team_home'], \n",
    "                              right_on=['month', 'DayofMonth', 'year', 'Home Team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get team information from team ID\n",
    "full_table = full_table.merge(teams_df,\n",
    "                              left_on=['team_favorite_id'], \n",
    "                              right_on=['team_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unneeded rows\n",
    "full_table = full_table.drop(columns=['Date_x', 'Month_x'\n",
    "                                        ,'schedule_date'\n",
    "                                        ,'Week'\n",
    "                                        ,'Month_y'\n",
    "                                        ,'year'\n",
    "                                        ,'Winner'\n",
    "                                        ,'Home Score'\n",
    "                                        ,'Away Score'\n",
    "                                        ,'Home Team'\n",
    "                                        ,'Away Team'\n",
    "                                        ,'Date_y'\n",
    "                                        ,'team_name_short'\n",
    "                                        ,'team_id'\n",
    "                                        ,'month_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stadium information\n",
    "full_table = full_table.merge(stadiums_df,\n",
    "                              left_on=['stadium'], \n",
    "                              right_on=['stadium_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "full_table.rename(columns = {'Day':'weekday'\n",
    "                             ,'Winner/tie':'winner'\n",
    "                             ,'Loser/tie':'loser'\n",
    "                             ,'PtsW':'pts_win' \n",
    "                             ,'PtsL':'pts_lose'\n",
    "                             ,'YdsW':'yds_win' \n",
    "                             ,'YdsL':'yds_lose'\n",
    "                             ,'TOW':'TO_win' \n",
    "                             ,'TOL':'TO_lose'\n",
    "                             ,'Year':'year'\n",
    "                             ,'weather_temperature':'w_temp'\n",
    "                             ,'weather_wind_mph':'w_wind_mph'\n",
    "                             ,'Overtime?':'overtime'\n",
    "                             ,'Playoff Game?':'playoff'\n",
    "                             ,'Home Odds Open':'home_odds_open'\n",
    "                             ,'Away Odds Open':'away_odds_open'\n",
    "                             ,'Total Score Open':'total_score_open'\n",
    "                             ,'team_name':'team_fav_name'\n",
    "                             ,'team_conference':'team_fav_conf'\n",
    "                             ,'team_division':'team_fav_div'\n",
    "                             }\n",
    "                             , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get yards, points, turnover differences\n",
    "full_table['yds_diff'] = full_table['yds_win'].astype(int) - full_table['yds_lose'].astype(int)\n",
    "full_table['pts_diff'] = full_table['pts_win'].astype(int) - full_table['pts_lose'].astype(int)\n",
    "full_table['TO_diff'] = full_table['TO_win'].astype(int) - full_table['TO_lose'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the difference rows\n",
    "full_table = full_table.drop(columns=['yds_win', 'yds_lose', 'pts_win', 'pts_lose', \n",
    "                                      'TO_win', 'TO_lose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table['schedule_week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = ''\n",
    "for i in range(1, 18):\n",
    "    if i == 17: \n",
    "        list = list + str(i)\n",
    "    else:\n",
    "        list = list + str(i) + '|'\n",
    "    \n",
    "full_table = full_table[full_table['schedule_week'].str.contains(list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert certain rows to integers\n",
    "full_table['schedule_week'] = full_table['schedule_week'].astype(str).astype(int)\n",
    "\n",
    "full_table['spread_favorite'] = full_table['over_under_line'].astype(str).astype(float).astype(int)\n",
    "\n",
    "full_table['w_temp'] = full_table['w_temp'].astype(int)\n",
    "full_table['w_wind_mph'] = full_table['w_wind_mph'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Model your outcome of interest. You should try several different approaches and really work to tune a variety of models before using the model evaluation techniques to choose what you consider to be the best performer. Make sure to think about explanatory versus predictive power, and experiment with both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = full_table.columns\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['year', 'DayofMonth', 'schedule_week', 'schedule_season', 'score_home', 'score_away', \n",
    "            'spread_favorite', 'over_under_line', 'w_temp', 'w_wind_mph','home_odds_open', 'away_odds_open', \n",
    "            'total_score_open','month', 'yds_diff', 'pts_diff', 'TO_diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_cols = ['stadium_neutral', 'overtime']\n",
    "\n",
    "new_cols = []\n",
    "for col in bin_cols:\n",
    "    new_col = 'd_' + col\n",
    "    full_table[new_col] = pd.get_dummies(full_table[col], drop_first=True)\n",
    "    full_table[new_col] = full_table[new_col].astype(int)\n",
    "    new_cols.append(new_col)\n",
    "    \n",
    "bin_cols = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['weekday'      \n",
    "            ,'winner'     \n",
    "            ,'loser'  \n",
    "            ,'team_home'\n",
    "            ,'team_away'\n",
    "            ,'stadium'\n",
    "            ,'team_fav_name'   \n",
    "            ,'team_fav_conf'\n",
    "            ,'team_fav_div'\n",
    "            ,'stadium_name'\n",
    "            ,'stadium_location'\n",
    "            ,'stadium_type'\n",
    "            ,'stadium_weather_type'\n",
    "            ,'stadium_surface']\n",
    "\n",
    "new_cols = []\n",
    "for col in cat_cols:\n",
    "    new_col = 'd_' + col\n",
    "    full_table[col] = pd.Categorical(full_table[col])\n",
    "    full_table[new_col] = full_table[col].cat.codes\n",
    "    new_cols.append(new_col)\n",
    "    \n",
    "cat_cols = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target: predict if home team will win based on previous 2 games\n",
    "\n",
    "https://stackoverflow.com/questions/53335567/use-pandas-shift-within-a-group/53335744#53335744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_df = full_table\n",
    "winner_df['f_week'] = winner_df['schedule_week'].astype(str).str.zfill(2)\n",
    "winner_df['f_team_home'] = winner_df['d_team_home'].astype(str).str.zfill(2)\n",
    "winner_df['game'] = winner_df['schedule_season'].astype(str) + winner_df['f_week'].astype(str) + winner_df['f_team_home'].astype(str)\n",
    "#winner_df['game'] = winner_df['game'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_df['prev1_winner'] = winner_df.groupby('game')['winner'].shift(1)\n",
    "winner_df[['schedule_season', 'schedule_week', 'team_home', 'f_team_home', 'prev1_winner']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_df['prev1_winner'] = winner_df['prev1_winner'].cat.add_categories('lost-game')\n",
    "winner_df['prev1_winner'].fillna('lost-game', inplace=True)\n",
    "\n",
    "# winner_df['prev2_winner'] = winner_df['prev2_winner'].cat.add_categories('lost-game')\n",
    "# winner_df['prev2_winner'].fillna('lost-game', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_df['prev1_winner'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#winner_df['prev2_winner'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_df[(winner_df['schedule_season'] == 2017) & (winner_df['schedule_week'] == 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_df[(winner_df['schedule_season'] == 2017) & (winner_df['schedule_week'] == 3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target: points difference based on several factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "numeric_df = full_table.select_dtypes(include=numerics)\n",
    "numeric_df.hist(bins=30, figsize=(15, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = numeric_df.columns\n",
    "\n",
    "x = 1\n",
    "plt.figure(figsize=(18,4))\n",
    "for col in cols:\n",
    "    plt.subplot(1,5,x)\n",
    "    plt.scatter(full_table[col], full_table[\"pts_diff\"])\n",
    "    plt.title(col)\n",
    "    \n",
    "    if (x == 5):\n",
    "        x = 1\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(18,4))\n",
    "    else:\n",
    "        x += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Violin plots and scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "ax = sns.violinplot(x=\"weekday\", y=\"pts_diff\", data=full_table)\n",
    "ax.set_ylabel('Points Difference (Home - Away)', fontsize=18)\n",
    "ax.set_xlabel('Weekday', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "x = np.array(full_table['TO_diff'])\n",
    "y = np.array(full_table['pts_diff'])\n",
    "plt.plot(x, y, 'o')\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "\n",
    "plt.plot(x, m*x + b)\n",
    "plt.xlabel('Turnover Difference (Home - Away)', fontsize=18)\n",
    "plt.ylabel('Points Difference (Home - Away)', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "x = np.array(full_table['away_odds_open'])\n",
    "y = np.array(full_table['pts_diff'])\n",
    "plt.plot(x, y, 'o')\n",
    "m, b = np.polyfit(x, y, 1)\n",
    "\n",
    "plt.plot(x, m*x + b)\n",
    "plt.xlabel('Away Odds Open', fontsize=18)\n",
    "plt.ylabel('Points Difference (Home - Away)', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr1 = full_table[num_cols + bin_cols]\n",
    "corrmap1 = corr1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmap1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr2 = full_table[cat_cols + ['pts_diff']]\n",
    "corrmap2 = corr2.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmap2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heat Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "sns.heatmap(corrmap1, square=True, annot=True, linewidths=.5)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "sns.heatmap(corrmap2, square=True, annot=True, linewidths=.5)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_cols = ['d_winner', 'd_loser']\n",
    "n_cols = ['score_home', 'score_away', 'away_odds_open', 'yds_diff', 'TO_diff', 'd_overtime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = full_table[c_cols + n_cols]\n",
    "y = full_table['pts_diff']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = ColumnTransformer([\n",
    "    # Should only use one of these\n",
    "    # Comment out or delete one of the below 2 lines\n",
    "#    ('OneHotEncoder', OneHotEncoder(drop=drop_cats), cat_cols),    \n",
    "    ('leaveoneoutencoder', LeaveOneOutEncoder(), c_cols),\n",
    "\n",
    "    # Scale numeric columns (not needed for all models but can't hurt)\n",
    "    ('scaler', StandardScaler(), n_cols)\n",
    "    \n",
    "    # bin_cols we'll leave untouch\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing),\n",
    "    # Choose your model and put it here\n",
    "    ('model', LassoCV())\n",
    "])\n",
    "\n",
    "\n",
    "grid = {\n",
    "    # Use model__ with hyperprammeter names after\n",
    "    'model__cv':[3, 5, 7],\n",
    "    'model__n_jobs': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "pipeline_cv = GridSearchCV(pipeline, grid)\n",
    "pipeline_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline_cv.score(X_train, y_train))\n",
    "print(pipeline_cv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing),\n",
    "    # Choose your model and put it here\n",
    "    ('model', RidgeCV())\n",
    "])\n",
    "\n",
    "\n",
    "grid = {\n",
    "    # Use model__ with hyperprammeter names after\n",
    "    'model__cv':[1, 3, 5]\n",
    "}\n",
    "\n",
    "pipeline_cv = GridSearchCV(pipeline, grid)\n",
    "pipeline_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline_cv.score(X_train, y_train))\n",
    "print(pipeline_cv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('preprocessing', preprocessing),\n",
    "    # Choose your model and put it here\n",
    "    ('model', ElasticNetCV())\n",
    "])\n",
    "\n",
    "\n",
    "grid = {\n",
    "    # Use model__ with hyperprammeter names after\n",
    "    \"model__n_jobs\": [0.1, 1, 10], \n",
    "    \"model__cv\": [3, 5, 7]\n",
    "}\n",
    "\n",
    "pipeline_cv = GridSearchCV(pipeline, grid)\n",
    "pipeline_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline_cv.score(X_train, y_train))\n",
    "print(pipeline_cv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate your best model on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RidgeCV(cv=3) \n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, to prepare for your presentation, create a slide deck and a 15-minute presentation that guides viewers through your model. Be sure to cover a few specific topics:\n",
    "\n",
    "* ## A specified research question that your model addresses\n",
    "* ## How you chose your model specification and what alternatives you compared it to\n",
    "* ## The practical uses of your model for an audience of interest\n",
    "* ## Any weak points or shortcomings of your model\n",
    "\n",
    "## This presentation is not a drill. You'll be presenting this slide deck live to a group as the culmination of all your work so far on supervised learning. As a secondary matter, your slides and the Jupyter Notebook should be worthy of inclusion as examples of your work product when applying to jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
